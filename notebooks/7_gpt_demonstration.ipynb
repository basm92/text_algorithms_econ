{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1UlNYIeI9gq"
      },
      "source": [
        "# **GPT Demonstration**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sekhansen/text_algorithms_econ/blob/main/notebooks/7_gpt_demonstration.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHItps9DI9gt"
      },
      "source": [
        "This notebook introduces how to use [OpenAI's API](https://openai.com/blog/openai-api) to interact with any GPT model. As a illustrative example, we will show how to use ChatGPT to classify a sequence of text from a job posting according to the extent to which it allows remote work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ukh4V_a1vlhl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install transformers openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "xk2jAzTUjT0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import GPT2TokenizerFast\n",
        "import time\n",
        "\n",
        "# add your OpenAI key\n",
        "openai.api_key = \"[YOUR-OPENAI-KEY]\""
      ],
      "metadata": {
        "id": "FmZ--bo1ycfs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## list all available models\n",
        "#openai.Model.list()"
      ],
      "metadata": {
        "id": "MCur3Bg3q2jQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt generation\n",
        "\n",
        "In order to obtain adequate results from the models, it's important to carefully craft prompts that define the task the we want the model to perform. In this case, we will create a prompt that gives a broad context related to the text, defines our four categories of interest, and specifies a format for the generated text. "
      ],
      "metadata": {
        "id": "WQBhCdThx7Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_generator(text):\n",
        "    wfh_prompt = f\"\"\"\n",
        "    You are a data expert working for the Bureau of Labor Statistics specialized in analyzing job postings. \n",
        "    Your task is to read the text of fragments of job postings and classify them into one of four categories based on the degree of remote work they allow. \n",
        "    The four categories and their definitions are:\n",
        "    \n",
        "    1. No remote work: The text doesn’t offer the possibility of working any day of the week remotely.\n",
        "    2. Hybrid work: The text offers the possibility of working one or more days per week remotely but not the whole week.\n",
        "    3. Fully remote: The text offers the possibility of working all days of the week remotely.\n",
        "    4. Unspecified remote: The text mentions the possibility of working remotely but doesn’t clearly specify the extent of this possibility.\n",
        "    \n",
        "    You always need to provide a classification. If classification is unclear, say “Could not classify”.\n",
        "    Please provide the classification and an explanation for your choice in the following format:\n",
        "    \n",
        "    - Classification: [Category Number] . [Category Name]\n",
        "    - Explanation: [Explanatory text]\n",
        "    \n",
        "    Text of job posting: \"{text}\"\n",
        "    \"\"\"\n",
        "\n",
        "    return wfh_prompt"
      ],
      "metadata": {
        "id": "QGM2eA1hxUYj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_posting = \"*This position is eligible for telework and other flexible work arrangements. Employee participation is at the discretion of the supervisor.\"\n",
        "prompt = prompt_generator(example_posting)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23xqvJ96xuVv",
        "outputId": "297f1b19-6b47-42d0-8711-21ed101a507a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    You are a data expert working for the Bureau of Labor Statistics specialized in analyzing job postings. \n",
            "    Your task is to read the text of fragments of job postings and classify them into one of four categories based on the degree of remote work they allow. \n",
            "    The four categories and their definitions are:\n",
            "    \n",
            "    1. No remote work: The text doesn’t offer the possibility of working any day of the week remotely.\n",
            "    2. Hybrid work: The text offers the possibility of working one or more days per week remotely but not the whole week.\n",
            "    3. Fully remote: The text offers the possibility of working all days of the week remotely.\n",
            "    4. Unspecified remote: The text mentions the possibility of working remotely but doesn’t clearly specify the extent of this possibility.\n",
            "    \n",
            "    You always need to provide a classification. If classification is unclear, say “Could not classify”.\n",
            "    Please provide the classification and an explanation for your choice in the following format:\n",
            "    \n",
            "    - Classification: [Category Number] . [Category Name]\n",
            "    - Explanation: [Explanatory text]\n",
            "    \n",
            "    Text of job posting: \"*This position is eligible for telework and other flexible work arrangements. Employee participation is at the discretion of the supervisor.\"\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate answers with GPT models\n",
        "\n",
        "Now that we have a prompt and an example to test it on, we will use [OpenAI's API](https://openai.com/blog/openai-api) to generate a response. Notice that the class that is used for interacting with ChatGPT (i.e. ChatCompletion) is not the same as the one to interact with other GPT models (i.e. Completion)."
      ],
      "metadata": {
        "id": "mMp2aSL10Rr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process prompt with chat-gpt\n",
        "response = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-3.5-turbo\",          # ChatGPT\n",
        "                    messages=[{\"role\": \"system\", \"content\": \"You are a data expert working for the Bureau of Labor Statistics specialized in analyzing job postings.\"},\n",
        "                              {\"role\": \"user\", \"content\": prompt}],\n",
        "                    n=1,\n",
        "                    temperature=0.1,                 # Higher values means the model will take more risks.\n",
        "                    max_tokens=50,\n",
        "                    top_p=1,\n",
        "                    frequency_penalty=0.0,\n",
        "                    presence_penalty=0.0,\n",
        "                    )\n",
        "\n",
        "print(response['choices'][0]['message']['content'].strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V8_OZRQy2dP",
        "outputId": "63868ff3-fc1a-4a5f-cd45-6ca9f9ad3416"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification: 4. Unspecified remote\n",
            "Explanation: The text mentions the possibility of telework and other flexible work arrangements, but it doesn't clearly specify the extent of this possibility. It only states that employee participation is at the discretion of the supervisor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # process prompt with GPT-3\n",
        "# response = openai.Completion.create(\n",
        "#                     model=\"text-davinci-003\",\n",
        "#                     prompt=prompt,\n",
        "#                     n=1,\n",
        "#                     temperature=0,                  # Higher values means the model will take more risks.\n",
        "#                     max_tokens=20,\n",
        "#                     top_p=1,\n",
        "#                     frequency_penalty=0.0,\n",
        "#                     presence_penalty=0.0,\n",
        "#                     stop=[\"\\n\"]                     # Up to 4 sequences where the API will stop generating further tokens.\n",
        "#                     )\n",
        "\n",
        "# print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTjR6uD_0KMK",
        "outputId": "5f1a644c-7db6-4f3c-fe8b-ed2f8f2f0fec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}